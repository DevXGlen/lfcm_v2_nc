{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import customDataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import lfcm\n",
    "import torch.nn as nn \n",
    "from pylab import zeros\n",
    "import torch.backends.cudnn as cudnn\n",
    "import trainingFunctions as t\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getenv('ROOT_PATH')\n",
    "split_train = 'train.csv'\n",
    "split_val = 'valid.csv'\n",
    "batch_size = 16 # 32\n",
    "workers = 4\n",
    "gpu = 0\n",
    "gpus = [0]\n",
    "weights = [0.33209667, 0.66790333] \n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "optimizer_name = 'ADAM'\n",
    "epochs = 32 # 301\n",
    "start_epoch = 0\n",
    "ImgSize = 299\n",
    "print_freq = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception v3 pretraining: Hardcoded strict=False, Might be omiting layers\n"
     ]
    }
   ],
   "source": [
    "model = lfcm.OldModel(gpu=gpu)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights).cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ADAM optimizer\n",
      "Using ADAM optimizer with: CNN lr: 1e-07 , mm_lr: 1e-06\n"
     ]
    }
   ],
   "source": [
    "if optimizer_name == 'ADAM':\n",
    "    print(\"Using ADAM optimizer\")\n",
    "    lr = 1e-6\n",
    "    cnn_lr = 1e-7\n",
    "\n",
    "if optimizer_name == 'ADAM':\n",
    "    print(\"Using ADAM optimizer with: CNN lr: \" + str(cnn_lr) + \" , mm_lr: \" + str(lr) )\n",
    "    optimizer = torch.optim.Adam([\n",
    "                    {'params': model.mm.parameters()},\n",
    "                    {'params': model.cnn.parameters(), 'lr': cnn_lr}],\n",
    "                                lr = lr)\n",
    "\n",
    "# print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model, device_ids=gpus).cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset.CustomDatasetFCM(root_dir, split_train, Rescale=0, RandomCrop=299, Mirror=True, embed_dir='train_embeddings')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     if train_dataset[i][0][0][0][0] != 0:\n",
    "#         print(f\"{i}\",train_dataset[i][0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# for t in train_dataset:\n",
    "#     if (t[1][0] == 0):\n",
    "#         print('image:', t[0])\n",
    "#         print('image text:', t[1])\n",
    "#         print('text:', t[2])\n",
    "#         print('label:', t[3])\n",
    "#         counter += 1\n",
    "#         break\n",
    "# print(train_dataset.id_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = customDataset.CustomDatasetFCM(\n",
    "    root_dir, split_val, Rescale=ImgSize,RandomCrop=0,Mirror=False, embed_dir='valid_embeddings')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "plot_data['train_loss'] = zeros(epochs)\n",
    "plot_data['train_acc'] = zeros(epochs)\n",
    "plot_data['train_acc_racist'] = zeros(epochs)\n",
    "plot_data['train_acc_notRacist'] = zeros(epochs)\n",
    "plot_data['train_acc_avg'] = zeros(epochs)\n",
    "plot_data['val_loss'] = zeros(epochs)\n",
    "plot_data['val_acc'] = zeros(epochs)\n",
    "plot_data['val_acc_racist'] = zeros(epochs)\n",
    "plot_data['val_acc_notRacist'] = zeros(epochs)\n",
    "plot_data['val_acc_avg'] = zeros(epochs)\n",
    "plot_data['epoch'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66790333, 0.33209667]\n",
      "tensor([0.6679, 0.3321], device='cuda:0')\n",
      "Epoch: 0\n",
      "TRAIN:: Acc: 61.331356048583984Acc Avg: 49.33364906123015 Racist Acc: 14.439981143394341 - Not Racist Acc: 84.22731697906595\n",
      "VALIDATION: Acc: 65.58303833007812Acc Avg: 49.361891347757066 Racist Acc: 1.0459363957597174 - Not Racist Acc: 97.6778462997544\n",
      "Saving Checkpoint\n",
      "Epoch: 1\n",
      "hmmmm total racist is 0?\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\John Glen\\AppData\\Local\\Temp\\ipykernel_28416\\2068271620.py\", line 13, in <module>\n",
      "    t.train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, gpu)\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\src\\training\\trainingFunctions.py\", line 40, in train\n",
      "    cur_acc_racist, cur_acc_notRacist = accuracy_per_class(output.data, target.long().cuda(gpu))\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\src\\training\\trainingFunctions.py\", line -1, in accuracy_per_class\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\John Glen\\Desktop\\Simplify\\PUP\\SY-2023-2024\\tool\\lfcm-racism\\venv\\Lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(class_weights)\n",
    "is_best = True\n",
    "val_acc_avg_best = 0\n",
    "epoch_best = -1\n",
    "epoch_loss_best = 0\n",
    "model_name = 'fcm_v2_b16_toy'\n",
    "best_loss = 0\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    plot_data['epoch'] = epoch\n",
    "\n",
    "    print('Epoch:', epoch)\n",
    "    t.train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, gpu)\n",
    "\n",
    "    plot_data = t.validate(val_loader, model, criterion, print_freq, plot_data, gpu)\n",
    "\n",
    "    # if (plot_data['val_acc_avg'][epoch]) > val_acc_avg_best:\n",
    "    #     racist_avg = plot_data['val_acc_racist'][epoch]\n",
    "    #     notRacist_avg = plot_data['val_acc_notRacist'][epoch]\n",
    "\n",
    "    #     if (notRacist_avg >= 40):\n",
    "    #         t.save_checkpoint(model, is_best, filename=f'checkpoints/{model_name}')\n",
    "    #         epoch_best = epoch\n",
    "    #         val_acc_avg_best = plot_data['val_acc_avg'][epoch]\n",
    "\n",
    "    if (plot_data['val_acc_avg'][epoch]) > val_acc_avg_best:\n",
    "        t.save_checkpoint(model, is_best, filename=f'checkpoints/{model_name}')\n",
    "        epoch_best = epoch\n",
    "        val_acc_avg_best = plot_data['val_acc_avg'][epoch]\n",
    "\n",
    "    # if best_loss == 0:\n",
    "    #     print('loss:', plot_data['val_loss'][epoch])\n",
    "    #     t.save_checkpoint(model, is_best, filename=f'checkpoints/val_loss_{model_name}')\n",
    "    #     epoch_loss_best = epoch\n",
    "    #     best_loss = plot_data['val_loss'][epoch]\n",
    "\n",
    "    # if (plot_data['val_loss'][epoch]) < best_loss:\n",
    "    #     print('loss:', plot_data['val_loss'][epoch])\n",
    "    #     t.save_checkpoint(model, is_best, filename=f'checkpoints/val_loss_{model_name}')\n",
    "    #     epoch_loss_best = epoch\n",
    "    #     best_loss = plot_data['val_loss'][epoch]\n",
    "    \n",
    "print(f'best model avg acc epoch: {model_name} epoch: {epoch_best} batch_size: {batch_size}')\n",
    "# print(f'best model loss epoch: {model_name} epoch: {epoch_best} batch_size: {batch_size}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
