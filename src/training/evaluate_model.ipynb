{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcm_result_txt = f\"{os.getenv('ROOT_PATH')}/results/fcm_result.txt\"\n",
    "lfcm_result_txt = f\"{os.getenv('ROOT_PATH')}/results/lfcm_result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(model, mode=\"classification\"):\n",
    "    sum_racist = 0\n",
    "    sum_notRacist = 0\n",
    "\n",
    "    model = model \n",
    "    results = []\n",
    "\n",
    "    text_file = \"\"\n",
    "\n",
    "    if model == 'fcm':\n",
    "        text_file = fcm_result_txt\n",
    "    elif model == 'lfcm':\n",
    "        text_file = lfcm_result_txt\n",
    "\n",
    "    # FCM score results\n",
    "    with open(text_file) as f:\n",
    "        for line in f:\n",
    "            data = line.split(',')\n",
    "            label = int(data[0])\n",
    "            notRacist_score = float(data[1])\n",
    "            racist_score = float(data[2])\n",
    "        \n",
    "            # default for classification\n",
    "            if mode == 'classification':\n",
    "                softmax_racist_score = np.exp(racist_score) / (np.exp(racist_score) + np.exp(notRacist_score))\n",
    "            \n",
    "            if label == 1:\n",
    "                sum_racist += softmax_racist_score\n",
    "            elif label == 0:\n",
    "                sum_notRacist += softmax_racist_score\n",
    "        \n",
    "            results.append([label, softmax_racist_score])\n",
    "\n",
    "    print(sum_notRacist, sum_racist) \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.5159525210982 238.7387398604339\n",
      "464.7220208626825 229.83683553867962\n"
     ]
    }
   ],
   "source": [
    "fcm_results = run_evaluation('fcm')\n",
    "lfcm_results = run_evaluation('lfcm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fcm_results)\n",
    "# print(lfcm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(data, filepath):\n",
    "    index = 0\n",
    "    for x in data:\n",
    "        print(len(data[x]))\n",
    "    with open(filepath, 'w', encoding='utf-8') as txt_file:\n",
    "        for i in range(len(data['thresholds'])):\n",
    "            txt_file.write(f\"{round(float(data['thresholds'][i]), 3)}:\\t\\t\\tf1({data['f1s'][i]})\\t\\t\\tacc({data['accuracies'][i]})\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(results, model_name):\n",
    "    thresholds = np.arange(0, 1, 0.001)\n",
    "    # thresholds = np.arange(0.4, 0.44, 0.0000001)\n",
    "\n",
    "    best_f = 0\n",
    "    best_th = 0\n",
    "    best_f_re = 0\n",
    "    best_f_pr = 0\n",
    "    best_accuracy = 0\n",
    "\n",
    "    acc_racist_best_accuracy = 0\n",
    "    acc_notRacist_best_accuracy = 0\n",
    "    best_acc_th = 0\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    fpr = []\n",
    "    tps = []\n",
    "    tns = []\n",
    "    fps = []\n",
    "    fns = []\n",
    "    ths = []\n",
    "\n",
    "    for th in thresholds:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "\n",
    "        for r in results:\n",
    "            if r[0] == 1 and r[1] >= th:\n",
    "                tp += 1\n",
    "            elif r[0] == 1 and r[1] < th:\n",
    "                fn += 1\n",
    "            elif r[0] == 0 and r[1] < th:\n",
    "                tn += 1\n",
    "            elif r[0] == 0 and r[1] >= th:\n",
    "                fp += 1\n",
    "\n",
    "        #  precision and recall\n",
    "        if tp > 0:\n",
    "            pr = tp / float((tp + fp))\n",
    "            re = tp / float((tp + fn))\n",
    "\n",
    "        # f1 score\n",
    "        if pr + re > 0:\n",
    "            f = 2 * (pr * re) / (pr + re)\n",
    "        else:\n",
    "            f = 0\n",
    "\n",
    "        accuracy_racist = re\n",
    "        if tn + fn > 0:\n",
    "            accuracy_notRacist = tn / float(tn + fp)\n",
    "        else:\n",
    "            accuracy_notRacist = 0\n",
    "        accuracy = (accuracy_racist + accuracy_notRacist) / 2\n",
    "\n",
    "        precisions.append(pr)\n",
    "        recalls.append(re)\n",
    "        f1s.append(f)\n",
    "        accuracies.append((tp + tn) / (tp + tn + fp + fn))\n",
    "        fpr.append(tn / float(tn + fp))\n",
    "\n",
    "        tps.append(tp)\n",
    "        tns.append(tn)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        ths.append(th)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            acc_racist_best_accuracy = accuracy_racist\n",
    "            acc_notRacist_best_accuracy = accuracy_notRacist\n",
    "            best_acc_th = th\n",
    "\n",
    "        if f > best_f:\n",
    "            best_f = f\n",
    "            best_th = th\n",
    "            best_f_pr = pr\n",
    "            best_f_re = re\n",
    "\n",
    "        # print(\"thr \" + str(th) + \" --> F1: \" + str(f) + \" PR: \" + str(pr) + \" RE: \" + str(re) + \" ACC Hate: \" + str(\n",
    "        #     accuracy_racist) + \" ACC NotHate: \" + str(accuracy_notRacist) + \" ACC mean: \" + str(accuracy))\n",
    "        \n",
    "        # print(tp, tn, fp, fn)\n",
    "    \n",
    "    x = {\n",
    "        'precisions': precisions,\n",
    "        'recalls': recalls,\n",
    "        'f1s': f1s,\n",
    "        'accuracies': accuracies,\n",
    "        'fpr': fpr,\n",
    "        'tps': tps,\n",
    "        'tns': tns,\n",
    "        'fps': fps,\n",
    "        'fns': fns,\n",
    "        'thresholds': thresholds \n",
    "    }\n",
    "\n",
    "    # print(x)  \n",
    "    write_results(x, f\"{os.getenv('ROOT_PATH')}/results/thresholds.txt\")\n",
    "    print(\"Best F1:  thr \" + str(best_th) + \" --> F1: \" + str(best_f) + \" PR: \" + str(best_f_pr) + \" RE: \" + str(best_f_re))\n",
    "    print(\"Best mean ACC:  thr \" + str(best_acc_th) + \" --> ACC: \" + str(best_accuracy*100) + \" Hate ACC: \" + str(\n",
    "        acc_racist_best_accuracy*100) + \" Not Hate ACC: \" + str(acc_notRacist_best_accuracy*100))    \n",
    "    \n",
    "\n",
    "    print('precision:', min(precisions), max(precisions))\n",
    "    print('recall:', min(recalls), max(recalls))\n",
    "    print('f1:', min(f1s), max(f1s))\n",
    "    print('accuracy:', min(accuracies), max(accuracies))\n",
    "\n",
    "    # # Print ROC curve\n",
    "    # plt.plot(recalls, fpr)\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.title(\"ROC \" + model_name)\n",
    "    # plt.show()\n",
    "\n",
    "    # auc = np.trapz(recalls, fpr)\n",
    "    # print('AUC:' + str(auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "Best F1:  thr 0.435 --> F1: 0.5021929824561403 PR: 0.33775811209439527 RE: 0.9786324786324786\n",
      "Best mean ACC:  thr 0.519 --> ACC: 53.928648707129724 Hate ACC: 62.39316239316239 Not Hate ACC: 45.46413502109704\n",
      "precision: 0.330028328611898 0.6666666666666666\n",
      "recall: 0.002136752136752137 1.0\n",
      "f1: 0.00425531914893617 0.5021929824561403\n",
      "accuracy: 0.3298022598870056 0.6701977401129944\n",
      "None\n",
      "0 1416\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(fcm_results, 'fcm'))\n",
    "fcm_threshold = 0.0\n",
    "# print(fcm_results)\n",
    "_r = 0\n",
    "_nr = 0\n",
    "for r in fcm_results:\n",
    "    # threshold for fcm\n",
    "    if r[1] >= fcm_threshold:\n",
    "        _r += 1\n",
    "    else:\n",
    "        _nr += 1\n",
    "\n",
    "print(_nr, _r)\n",
    "print((_r) / (_r + _nr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "Best F1:  thr 0.441 --> F1: 0.49786324786324787 PR: 0.3319088319088319 RE: 0.9957264957264957\n",
      "Best mean ACC:  thr 0.47700000000000004 --> ACC: 53.05907172995781 Hate ACC: 83.33333333333334 Not Hate ACC: 22.78481012658228\n",
      "precision: 0.13333333333333333 0.36363636363636365\n",
      "recall: 0.002136752136752137 1.0\n",
      "f1: 0.004228329809725159 0.49786324786324787\n",
      "accuracy: 0.3298022598870056 0.6694915254237288\n",
      "[[1, 0.4971608228665581], [0, 0.4944499854623517], [0, 0.495740563273872], [1, 0.5172420235602779], [1, 0.49139282857582994], [0, 0.5282944003679252], [1, 0.49838731158964267], [0, 0.49716409542868395], [0, 0.4821800250337796], [0, 0.49156056828918615], [0, 0.49274186182879454], [0, 0.48110991303392425], [0, 0.5026539203138589], [1, 0.47855707482990667], [1, 0.5143135223435475], [0, 0.5335798082793655], [0, 0.4624013815954899], [1, 0.4564455738784724], [1, 0.49712895963498605], [0, 0.49493250699129393], [0, 0.4575597944304519], [1, 0.49713201054725087], [0, 0.48618198417247865], [0, 0.5144460939362279], [1, 0.49716406003956465], [0, 0.46735535000266837], [0, 0.5025151010809584], [0, 0.45661943538005734], [0, 0.47126960743397167], [1, 0.48857894028134097], [0, 0.48776418675981825], [1, 0.5026384458913977], [0, 0.49716407121507594], [0, 0.48588598347585776], [0, 0.47512118072304727], [0, 0.4862066789070313], [0, 0.49539761578248326], [0, 0.46560644594924544], [0, 0.5025165613577839], [1, 0.5127457347401021], [1, 0.49706090087892424], [0, 0.5012190345735179], [0, 0.4959061376123088], [0, 0.497142807947255], [0, 0.46731711173603335], [0, 0.5026537787568155], [1, 0.4786517503034256], [0, 0.49770045039145805], [0, 0.4954245771624509], [0, 0.502547696535553], [0, 0.46140810307326424], [1, 0.4429582305167874], [0, 0.4928808818744454], [0, 0.48875152526584215], [1, 0.4953558700236178], [1, 0.49458699262067685], [0, 0.5005399228769002], [1, 0.4901404326117648], [0, 0.47178704645594755], [1, 0.49716405631439414], [1, 0.49542455108760247], [0, 0.5026526761019372], [1, 0.48706774662540103], [0, 0.48116789650779135], [1, 0.45642885598965455], [1, 0.49667285078309314], [1, 0.47022861547904005], [0, 0.5026079813059071], [1, 0.4833081919064531], [1, 0.4861972173612992], [0, 0.5144106326491711], [0, 0.49741078992486504], [1, 0.49716332618099107], [0, 0.4971634714626366], [0, 0.49716404886405324], [0, 0.45501914948227923], [1, 0.4845288369378189], [1, 0.4971608042407072], [0, 0.4596360055909812], [0, 0.49341954150472356], [1, 0.4984347349874771], [1, 0.49716407680283164], [0, 0.49784578598320317], [0, 0.49716407121507594], [0, 0.4905400148415011], [1, 0.4888280261399704], [0, 0.5026522067285689], [0, 0.47520531318845033], [0, 0.49541503144147525], [1, 0.5024904682160746], [0, 0.5022806180804003], [0, 0.4562841414812497], [0, 0.4274200571271873], [0, 0.49235883245262874], [0, 0.51322315352998], [0, 0.5144462730661664], [0, 0.5144457175307084], [0, 0.497162949938783], [1, 0.4971492096500517], [0, 0.4711266011878211], [0, 0.45459282147163893], [0, 0.5026522067285689], [1, 0.4835401266114096], [0, 0.49173898552863154], [0, 0.5026539259016369], [0, 0.5124813613906556], [0, 0.48146003681451954], [0, 0.4971633131428947], [0, 0.4959182453934152], [1, 0.49716410101643954], [0, 0.44491412697809934], [1, 0.49831567224210893], [0, 0.4961836352757208], [0, 0.4935917810395889], [1, 0.5497698985295976], [1, 0.4971568890870225], [0, 0.4565483113770656], [0, 0.4697978779198708], [0, 0.49716408611575774], [0, 0.49536489329669536], [0, 0.4591639916716541], [0, 0.5143624738153367], [1, 0.5026215000146868], [0, 0.49716408797834305], [1, 0.5023060370639857], [1, 0.5144463851968535], [0, 0.4935199223492683], [0, 0.47028679860628153], [1, 0.4312572131252635], [0, 0.5026539054131175], [0, 0.49716398739874085], [0, 0.49707098302992814], [0, 0.5026539426649709], [0, 0.4949485823010795], [0, 0.4549371305795607], [0, 0.502638037983467], [0, 0.49711326923243454], [0, 0.4971639203456728], [0, 0.4971639818109852], [0, 0.47567790520983233], [0, 0.49716408239058735], [1, 0.4860502585050227], [1, 0.4944346168136445], [1, 0.49624151924013077], [0, 0.4756432798555212], [0, 0.4759811743449849], [1, 0.49853339839376803], [0, 0.5012236851050449], [1, 0.48331537742852054], [0, 0.4954245450345126], [0, 0.4971636484082313], [0, 0.5144461311580336], [0, 0.5011935658433206], [0, 0.5026538141460765], [1, 0.48611625487205157], [0, 0.48537472075935983], [0, 0.45913698874538594], [1, 0.5026539203138589], [0, 0.4712480353617914], [0, 0.49879302318888824], [0, 0.456284802286658], [0, 0.5026536409249572], [0, 0.45628153985026354], [1, 0.4562814557478452], [1, 0.5145344292041149], [1, 0.49690045661534743], [0, 0.488633145476741], [0, 0.4480012614452632], [0, 0.4704900540197295], [0, 0.49542452361588724], [0, 0.48182039119879216], [1, 0.47824209398523587], [0, 0.4997172884478696], [0, 0.5411040847926765], [1, 0.49139278016140714], [0, 0.5022650094365748], [1, 0.47606928268544263], [1, 0.49542458926863053], [0, 0.4971578594937788], [1, 0.4962757220091377], [0, 0.4910256503885141], [0, 0.5026470231326877], [0, 0.5144496825828353], [0, 0.5026275646201919], [0, 0.4860634488058361], [1, 0.5026538607108934], [0, 0.4424351874998491], [1, 0.4944932889957953], [0, 0.4968210849840017], [1, 0.4970491442706122], [1, 0.49219252117996737], [0, 0.49193606976303217], [1, 0.4562841054373227], [0, 0.4860509722734492], [1, 0.45555689001741045], [1, 0.48389730688491867], [0, 0.4971637881021223], [1, 0.49716370801095805], [1, 0.4970425581872795], [0, 0.49708320901486835], [0, 0.4913928248516435], [1, 0.49897999830478423], [1, 0.4955364999518589], [1, 0.4918571460093845], [1, 0.49497898922622624], [1, 0.4954180775416257], [0, 0.49715162355975756], [0, 0.4562931173575129], [0, 0.4971640917035135], [1, 0.48817337445020265], [0, 0.4971540747212923], [0, 0.47151518679227794], [0, 0.514446467084823], [0, 0.5026538178712618], [0, 0.4971640842531726], [1, 0.4562813383741447], [0, 0.4843762947029977], [1, 0.49802691535758], [0, 0.4854028896809762], [1, 0.4563206837892065], [1, 0.5016932180617679], [1, 0.5024203692565682], [0, 0.49702875647186245], [0, 0.48439389023216894], [1, 0.4936756390936791], [0, 0.49696389871457314], [0, 0.49716401720010445], [0, 0.4888255682107213], [0, 0.49716408239058735], [0, 0.45628132543531175], [0, 0.49708146563837446], [0, 0.49716409356609875], [0, 0.4555098966589861], [0, 0.5024229117075564], [0, 0.4971640414137123], [0, 0.49716410101643965], [1, 0.4917058939993065], [0, 0.497164013474934], [1, 0.4562816026960284], [0, 0.4962682122414091], [1, 0.5026515268822138], [0, 0.48445190043912345], [0, 0.5026538029705203], [1, 0.5209800872323517], [0, 0.4971308259439285], [0, 0.46503141095041556], [0, 0.47105850866196425], [0, 0.4970596697130407], [1, 0.46335875158085565], [0, 0.4971641010164397], [0, 0.4953091272919646], [0, 0.4971640842531726], [0, 0.50262020737447], [0, 0.486186995515593], [0, 0.4813001384440203], [1, 0.4978140322068727], [0, 0.5026539203138589], [0, 0.49716371173612844], [0, 0.5026538607108932], [1, 0.4954245604000484], [0, 0.471269668698313], [1, 0.49800984168900647], [0, 0.5004057380411532], [0, 0.5026521080111536], [1, 0.4562813494645728], [0, 0.4769252648763859], [0, 0.4971638607429458], [0, 0.4880363860241259], [0, 0.4836083179514119], [1, 0.49628830627521897], [0, 0.4562813476161681], [1, 0.502653426726798], [0, 0.4977698669577704], [0, 0.48169340328022897], [0, 0.5144462688787134], [0, 0.4891315098148105], [0, 0.49714550869461116], [0, 0.4983405047495742], [1, 0.49716408052800215], [0, 0.45714701830689414], [0, 0.4954123494581331], [0, 0.4971586008026011], [1, 0.49716400229942265], [0, 0.4569229178792597], [0, 0.4562815176694058], [1, 0.5104199576850551], [0, 0.45694932653934267], [0, 0.49716397436064425], [0, 0.4850947729866055], [1, 0.5026537321919986], [0, 0.4971640898409283], [0, 0.487756004874751], [0, 0.49812171653558485], [0, 0.4968485020218336], [0, 0.4950983869926847], [0, 0.4612855452638368], [0, 0.45935574903262766], [1, 0.4714274772535492], [0, 0.512452707984671], [0, 0.5026332622940084], [0, 0.4921613108895065], [1, 0.4963078611146469], [0, 0.47601567513395915], [1, 0.49289058754997916], [1, 0.4969865876960842], [0, 0.5026522644689438], [0, 0.5026536819019962], [1, 0.45852791659737346], [0, 0.4736506747340808], [1, 0.4708517411608098], [1, 0.4872963160922809], [0, 0.4555724533174707], [0, 0.48158137119512684], [1, 0.5026534621160592], [1, 0.5144162280382445], [0, 0.5144503004645332], [0, 0.4953393046263533], [1, 0.5144438396903199], [1, 0.45628196868021575], [0, 0.49539260243267164], [1, 0.48533893188394855], [1, 0.4971419530210577], [0, 0.4914833619656665], [0, 0.49716407866541684], [0, 0.4790025413206082], [1, 0.5265720249022302], [0, 0.49683297190662606], [0, 0.4835183554510217], [1, 0.5026539277642296], [0, 0.5127453080061707], [0, 0.4620730012595366], [1, 0.4913928267137367], [0, 0.494701197380706], [0, 0.4969339270762445], [0, 0.5143852960904257], [0, 0.4780455532682792], [1, 0.4877548349043493], [0, 0.49628134222951314], [1, 0.4913910418975289], [0, 0.5024200693777255], [0, 0.45628138366006005], [0, 0.4562816812532363], [0, 0.49716352361502236], [1, 0.4971640674899056], [0, 0.49616450004557433], [0, 0.5348931670024615], [1, 0.4856024746080744], [1, 0.4862723227819968], [0, 0.5026505806850786], [0, 0.49806102045036504], [1, 0.5026538458101519], [0, 0.4831293170602319], [1, 0.5023926835404449], [0, 0.4562903733906795], [1, 0.5238041487155368], [0, 0.47126960279273383], [0, 0.46259622031106373], [0, 0.4846870717493967], [1, 0.5022971710609458], [0, 0.4673492457088506], [0, 0.5026412472316122], [1, 0.4712696510616086], [0, 0.46086843536642075], [0, 0.49716408797834305], [0, 0.4711770398605865], [0, 0.45936934348972225], [0, 0.5025375677331686], [0, 0.5026539259016369], [0, 0.5392207420573821], [0, 0.47767686794918934], [1, 0.4562929251226331], [1, 0.5026539016879322], [0, 0.4954245189596643], [0, 0.5026162474994674], [0, 0.4559493871323279], [0, 0.49771148074383326], [0, 0.4587114938617789], [0, 0.5011980734187985], [0, 0.5026539165886735], [0, 0.49716408984092825], [1, 0.49716352361502236], [1, 0.4854112197789022], [1, 0.4926478816442258], [0, 0.5023104756527781], [0, 0.48486923150740946], [1, 0.5025490878953349], [1, 0.5026471516516007], [0, 0.49844834613466815], [0, 0.47127031661518687], [0, 0.5013051618049139], [0, 0.49845501154641797], [1, 0.4971639240708433], [1, 0.4969318577553523], [0, 0.4938819295583455], [0, 0.49716405631439414], [1, 0.5026538290468178], [1, 0.497164095428684], [0, 0.4954245389814228], [0, 0.49716291454966455], [0, 0.5026536390623645], [0, 0.4651818043588385], [0, 0.4971550171892136], [0, 0.5021820078850935], [1, 0.48345015840811395], [0, 0.4830154417414853], [0, 0.5025823668998839], [1, 0.4898077968333244], [0, 0.5035782981695324], [1, 0.5026539147260809], [1, 0.4945333450124045], [0, 0.4643275725796687], [1, 0.49716409356609875], [0, 0.49613973345425255], [0, 0.48126986915509484], [0, 0.49806003233198115], [0, 0.4971640749402464], [1, 0.4834539740436662], [0, 0.4955325533216033], [0, 0.502653937077193], [0, 0.4853920415830343], [0, 0.5026538849245982], [1, 0.479129141275589], [0, 0.5025775725789219], [0, 0.5024949254151342], [0, 0.4563343307830132], [1, 0.4562854806520904], [0, 0.497160306930491], [0, 0.4857137049348851], [0, 0.498263252433238], [0, 0.49451487444479236], [1, 0.4980967304395456], [1, 0.4933581645753033], [0, 0.5026491204122971], [0, 0.4712697188236836], [0, 0.4627736493344298], [1, 0.4954245264096209], [1, 0.5134250358160036], [0, 0.5025255428043538], [0, 0.4780687668580395], [0, 0.47672227316630605], [0, 0.4961912754018848], [1, 0.48194524965742386], [1, 0.4978433552764554], [1, 0.49716375830075876], [0, 0.4971573100312174], [1, 0.4760016175946542], [1, 0.5024208293191372], [0, 0.49542462325905806], [0, 0.4977548366437772], [0, 0.4725281247760683], [1, 0.46088135517034867], [0, 0.4712696417791326], [0, 0.5026538867871908], [0, 0.45628142709757147], [0, 0.4567579838656841], [1, 0.45628134946457277], [0, 0.5133339218304068], [1, 0.4826702302476732], [0, 0.4967031397894364], [1, 0.4562813697970246], [0, 0.5026538979627468], [0, 0.45552063296529105], [0, 0.49686316790977997], [0, 0.4708626725496236], [0, 0.4971633969592286], [1, 0.4967615125950931], [1, 0.497133521102792], [0, 0.49580771288804826], [1, 0.499668292749908], [0, 0.49380811026570304], [0, 0.4971640376885419], [0, 0.4971199614938928], [1, 0.4827611419623747], [0, 0.501619158240706], [0, 0.5026538718864493], [0, 0.4935729798033763], [0, 0.5824247900065068], [1, 0.49738441185886695], [0, 0.4971390865039298], [0, 0.5132589010084448], [0, 0.5026538979627468], [0, 0.49227326598408766], [1, 0.4562915175570595], [0, 0.4954325248705389], [1, 0.5221195465632543], [1, 0.5024916099892103], [1, 0.5026539072757102], [0, 0.49140047805664794], [0, 0.5026491371756329], [1, 0.48167038072956514], [0, 0.49850470878789427], [0, 0.4961888801793025], [0, 0.5026530821471488], [1, 0.49560445602020003], [1, 0.47984944961037096], [0, 0.5013959352910857], [0, 0.49800966148094367], [0, 0.466496880330627], [1, 0.4585774656460307], [1, 0.48547586950490124], [0, 0.4712696519898561], [0, 0.4562815657279313], [1, 0.5019021966923854], [0, 0.45349900263468723], [0, 0.4971634714626367], [0, 0.497160163511441], [1, 0.49800967731317664], [0, 0.49635223065685813], [0, 0.4612070852081681], [1, 0.4971640898409283], [0, 0.5026538905123761], [0, 0.5030149628996498], [1, 0.49841702885818445], [0, 0.49716408984092825], [1, 0.4971143625687058], [1, 0.49542454503451266], [1, 0.49098092087890227], [0, 0.4934886472973736], [0, 0.4971273112484117], [0, 0.5026162530872498], [0, 0.5173761607263453], [1, 0.49716407680283164], [0, 0.4542066179192984], [1, 0.44287193393870133], [0, 0.4970759840608226], [0, 0.47126964085088496], [0, 0.5026539165886735], [1, 0.49716406376473504], [0, 0.4948184370821938], [0, 0.4712703370366372], [1, 0.4864269690300182], [0, 0.5144340419723825], [1, 0.5025949636313661], [0, 0.4922219792062516], [0, 0.4954082920275861], [0, 0.5026534230016126], [0, 0.5026538905123761], [1, 0.445408877113938], [0, 0.5026378908385962], [0, 0.49688676483936034], [0, 0.5016980832349432], [1, 0.48214074441840626], [1, 0.5026538830620054], [0, 0.5026539277642296], [0, 0.4971638737810423], [1, 0.5026536111234742], [1, 0.4971640768028317], [0, 0.4712696492051134], [1, 0.4813499370100116], [0, 0.5092538062287821], [1, 0.47177071992955083], [1, 0.49535320108352543], [0, 0.4590656142537931], [1, 0.4971638383919231], [1, 0.5026245174167852], [0, 0.4969339382516952], [0, 0.4922194698994841], [1, 0.49542453385957763], [0, 0.4971640898409283], [0, 0.49514442207538206], [0, 0.4954245427064011], [0, 0.4954245468970018], [0, 0.4562843595932276], [0, 0.5211087465048855], [0, 0.4815916604432765], [1, 0.4971640842531726], [0, 0.50203870597176], [0, 0.49714275206972514], [0, 0.5143832344529446], [0, 0.48782563371239235], [0, 0.5026538327720032], [0, 0.5024473210932481], [0, 0.5127420877233417], [0, 0.4971640768028317], [1, 0.4827122658144658], [0, 0.45628137441803646], [1, 0.4564670056012721], [1, 0.4933420555447], [0, 0.49495149750899325], [1, 0.4924856839025088], [0, 0.4562813494645729], [0, 0.496639017347445], [1, 0.5954982651828642], [0, 0.5026526425752681], [0, 0.49716409356609875], [0, 0.4676881737189568], [0, 0.47495761559316524], [0, 0.456281342070954], [0, 0.5026539165886735], [1, 0.4971640954286839], [1, 0.49852925776932694], [0, 0.5026539128634883], [0, 0.5024215445581028], [1, 0.4562908493564438], [0, 0.4960231911809398], [1, 0.5142630263251181], [0, 0.4400053483943083], [0, 0.4970917619911729], [0, 0.5026439349534838], [0, 0.4971575111903916], [0, 0.4971610053998974], [0, 0.456281393826286], [0, 0.4949613103220535], [0, 0.4562963742619736], [0, 0.5013825299374359], [1, 0.49800965030524985], [0, 0.4673153182544615], [1, 0.5131142266810023], [0, 0.48534364497834626], [0, 0.5045801414534665], [1, 0.5008358295671888], [0, 0.5143304966601089], [0, 0.49716409356609875], [0, 0.49343284873495585], [0, 0.47603966800057956], [1, 0.4971639203456728], [0, 0.5055632083518595], [0, 0.479994653683068], [1, 0.48118834169025276], [0, 0.49774008013708443], [1, 0.4971185533809035], [0, 0.4901965141413405], [0, 0.4563237410945943], [0, 0.49524154352261907], [0, 0.48436478875606476], [1, 0.48621543784851085], [0, 0.4971640339633714], [1, 0.5124187752953581], [0, 0.45628174502320673], [0, 0.4967031397894364], [0, 0.4562904907647538], [1, 0.49822588450688027], [0, 0.5026277434291876], [1, 0.4536905412931991], [0, 0.47026187076958287], [1, 0.5023265573851972], [0, 0.4953925949827238], [0, 0.5143306739313178], [1, 0.5025597959628022], [0, 0.5426197376437637], [0, 0.4755855771816672], [0, 0.5026496549764456], [1, 0.45724747790954146], [0, 0.49715933093592585], [0, 0.49716399298649655], [0, 0.502647108811963], [0, 0.49894983103324203], [0, 0.49716380859055964], [0, 0.46153769962520375], [0, 0.4971640190626897], [0, 0.49487802888053595], [0, 0.49837708856876856], [0, 0.48961665631054213], [0, 0.4954245771624509], [0, 0.5026539352146003], [0, 0.49716397436064425], [1, 0.4970906183657582], [1, 0.4993113358203192], [1, 0.4971272907599914], [1, 0.4950538973716226], [0, 0.46588997545129435], [1, 0.4971465051772984], [0, 0.4971305614570276], [0, 0.49540720712831116], [0, 0.4997880272694265], [0, 0.47758921021744205], [1, 0.50263106257105], [0, 0.4966724503321208], [0, 0.5025061028691159], [0, 0.49626500587655864], [1, 0.49371780360908246], [0, 0.501223664616071], [0, 0.4983201034247662], [0, 0.49716368752252077], [0, 0.4971585467876362], [0, 0.49309315045161906], [1, 0.48109396924872894], [0, 0.49671728224178835], [1, 0.4873573809109248], [0, 0.5016675157116588], [0, 0.49710062415787604], [0, 0.4701053084017914], [0, 0.4961979358351164], [1, 0.49716366144632773], [1, 0.4562821599901507], [0, 0.47858771809956363], [0, 0.49542452454713176], [0, 0.4712696278554187], [0, 0.48022111177018967], [1, 0.4977659983208932], [1, 0.4555204259999594], [0, 0.49590526222778986], [1, 0.5144397769282025], [0, 0.4712704187224394], [0, 0.49557241729268503], [0, 0.49892816670506734], [0, 0.5017822830887941], [0, 0.49181349724906853], [0, 0.5143498754992695], [0, 0.49101302340099395], [0, 0.5026538718864494], [1, 0.4699258917261263], [1, 0.4971540039430698], [0, 0.47294543996643423], [0, 0.4755208800341697], [0, 0.49715978726925986], [0, 0.4966081863882633], [0, 0.5026440001442412], [1, 0.49511536896462477], [0, 0.48357156707935667], [1, 0.4964723464572703], [0, 0.4914070168017811], [1, 0.49535970813873315], [0, 0.4586135108715854], [0, 0.4971641066041953], [0, 0.4527145041375997], [0, 0.4970288458756724], [1, 0.49683964922214413], [0, 0.4862066789070313], [0, 0.5144404594835381], [0, 0.5026435531219037], [1, 0.502641224880494], [1, 0.48296058801722547], [1, 0.4557017935715602], [0, 0.502653920313859], [0, 0.49704550478891535], [0, 0.4971631678612497], [0, 0.49542455527820317], [0, 0.4971541715757022], [0, 0.49661779067723905], [0, 0.49716348263814786], [0, 0.49529100163105527], [0, 0.5026497592816445], [0, 0.4712696380661422], [1, 0.4971002050768119], [0, 0.460748231322338], [0, 0.5026539184512663], [1, 0.4811068291769963], [0, 0.49716408052800215], [0, 0.5026539147260809], [0, 0.49669528163203197], [0, 0.5026538234590398], [0, 0.4954071568411355], [0, 0.4971640209252749], [0, 0.45628236054212523], [0, 0.5026538961001542], [0, 0.5026538011079277], [0, 0.5020654810447576], [0, 0.49716230734690037], [0, 0.48342064927919076], [1, 0.47614830652602524], [0, 0.4971623799877214], [0, 0.5401906003304657], [0, 0.47484751149020493], [0, 0.503519117463908], [0, 0.4980604709783118], [1, 0.5144586404673137], [0, 0.5007060074677595], [0, 0.495034121282909], [1, 0.48348409218843585], [0, 0.4607693735601665], [0, 0.4856330078803109], [1, 0.4971640917035135], [0, 0.4857878626850811], [0, 0.46960925236218026], [1, 0.456281357782394], [1, 0.49523685054801253], [0, 0.49716396877288865], [0, 0.49716214530199243], [0, 0.4945446676127568], [1, 0.503578322382679], [0, 0.4971589472434118], [0, 0.4833484096152154], [1, 0.4889501218116009], [0, 0.49716171690741073], [0, 0.5026539165886735], [0, 0.5026538532605226], [1, 0.49696541950828915], [0, 0.4562916543395009], [1, 0.4971640991538544], [1, 0.5026495748849534], [1, 0.4984941751587885], [1, 0.5026513350351584], [1, 0.49542113761078344], [1, 0.45629717739818265], [1, 0.4965316352756011], [1, 0.50265385139793], [0, 0.4997718706885328], [0, 0.5178498361043613], [0, 0.4971176090511863], [0, 0.4817337983786454], [0, 0.4562813291321212], [0, 0.49716343979868827], [0, 0.46128691628370116], [0, 0.49716178768564573], [0, 0.5127380502689824], [0, 0.4712701792345236], [0, 0.48626315431298883], [0, 0.45643617051606183], [0, 0.4948980865406653], [0, 0.45713108028912963], [0, 0.4971386934986723], [0, 0.46134096511187855], [0, 0.5017357790029638], [1, 0.4746704314880327], [0, 0.4562816211800771], [1, 0.5204898891254581], [1, 0.4752347868262057], [0, 0.4602776440483277], [0, 0.5012230112971959], [0, 0.497791332588845], [0, 0.5026488298478097], [0, 0.497635369123237], [1, 0.4863918515372463], [0, 0.5026487329929802], [0, 0.4628823378372257], [0, 0.4562813439193587], [1, 0.49716407680283164], [0, 0.5024513536232251], [0, 0.5022006656431693], [0, 0.4971603087930761], [0, 0.5026506123491563], [0, 0.5144449121438128], [0, 0.48888786101242365], [0, 0.49714899545282354], [1, 0.36339140915931983], [0, 0.4746081209500823], [0, 0.4712696538463513], [0, 0.47263287364048007], [0, 0.4815348274932346], [0, 0.4562817616588515], [1, 0.4971641159171215], [0, 0.5133622608572208], [0, 0.502648092261026], [0, 0.49686417183601306], [0, 0.5026538961001541], [0, 0.4858670889900441], [1, 0.5026539259016369], [1, 0.5000510029492993], [1, 0.5026539333520076], [1, 0.5010070526393463], [1, 0.5026537973827424], [0, 0.45733067757976403], [1, 0.4966587660868122], [1, 0.4557446181740429], [0, 0.49490556335220504], [1, 0.4562814234007619], [1, 0.48221453515827595], [0, 0.4712703862337679], [0, 0.49714533361167407], [1, 0.4971640693524908], [1, 0.4954245771624509], [0, 0.49692812515519696], [0, 0.5026539184512663], [0, 0.4825551031019747], [1, 0.4996495806254476], [0, 0.4971641010164396], [0, 0.49716398181098514], [0, 0.4971119374855658], [0, 0.5144480853026091], [1, 0.4987926888460328], [0, 0.4936480070028586], [0, 0.5024207715784911], [1, 0.49702991872140745], [0, 0.4913926740220964], [1, 0.4556095352344975], [1, 0.4982713641554488], [0, 0.4687854009290896], [1, 0.49716332431840593], [0, 0.4885838755783485], [1, 0.5026505844102642], [0, 0.49716408239058735], [0, 0.49700225756348826], [0, 0.5086109319208699], [0, 0.4971639873987408], [0, 0.4939425310463028], [0, 0.4854429788168302], [1, 0.502583531022035], [0, 0.49716352361502236], [1, 0.5026536614134768], [0, 0.49716148780944047], [0, 0.4999921731650836], [1, 0.4845565112567272], [1, 0.4562813494645729], [1, 0.49705597249044275], [0, 0.5026539165886735], [0, 0.47126965663109405], [1, 0.49471277521667195], [0, 0.4726695118225018], [0, 0.47578648039635335], [1, 0.4968627860825551], [1, 0.5015890805564319], [0, 0.5026140533635062], [0, 0.5026539165886735], [0, 0.4971640656273203], [1, 0.477357113820638], [0, 0.4562813263595142], [0, 0.4569893467328085], [0, 0.46088099140097044], [1, 0.45628141046192866], [0, 0.5026538309094105], [0, 0.5026442925713513], [0, 0.49716408611575774], [0, 0.5026530840097415], [1, 0.4987188624315185], [1, 0.4971638607429457], [0, 0.502653162238635], [0, 0.5024202090728388], [0, 0.4157670723826993], [0, 0.49800965263351943], [0, 0.4562861867438026], [0, 0.47653088224979423], [0, 0.48466782450313156], [1, 0.4811308806952012], [0, 0.44630274598556513], [0, 0.4971439050094367], [0, 0.49802087861894634], [0, 0.4562813975230955], [0, 0.49774918176741345], [1, 0.5144162471144857], [0, 0.49716406935249075], [0, 0.502516164624416], [0, 0.4657399631096227], [0, 0.49975229429244944], [0, 0.4969667754640322], [1, 0.5025959377685298], [0, 0.5027252147191452], [0, 0.46960921162236546], [1, 0.5033825208359061], [1, 0.4555246872714042], [1, 0.5262721592007172], [0, 0.47616651568910917], [0, 0.4750350552209333], [1, 0.49716397436064425], [1, 0.5011091763585551], [1, 0.49767739133716665], [0, 0.5144462851632531], [1, 0.50265385139793], [0, 0.5149900598070389], [0, 0.4904809492954467], [0, 0.5026483679247747], [0, 0.4987318338080361], [0, 0.44576113727571753], [1, 0.4562814344911904], [0, 0.49306194688311955], [0, 0.513192255195616], [0, 0.5437256199367979], [1, 0.5011935658433205], [1, 0.5026538458101519], [0, 0.48577857466959834], [0, 0.45628141231033337], [1, 0.497164013474934], [1, 0.49542458926863053], [1, 0.5024208311817389], [1, 0.50173549402169], [0, 0.5005869760275499], [1, 0.4821053073184682], [1, 0.5076030136107156], [0, 0.47789644748013815], [0, 0.4867015894397064], [1, 0.5026538998253396], [0, 0.49716259418501496], [1, 0.49716262212379236], [1, 0.4984305021679707], [1, 0.493100198288446], [1, 0.49708588181978036], [1, 0.5026538420849666], [0, 0.4949930214492106], [0, 0.4847823019033068], [0, 0.5024208125557239], [0, 0.49510050275431094], [0, 0.49453083167338735], [0, 0.5026510183943856], [1, 0.49716374712524747], [1, 0.5026531212615956], [1, 0.48254750485816067], [0, 0.4980096773131766], [0, 0.5127156152831311], [1, 0.4562867837796022], [0, 0.5667176517368181], [0, 0.5026538998253395], [1, 0.49542453479082227], [0, 0.4957758094337447], [0, 0.4777004782989429], [0, 0.510674275274459], [1, 0.5021117427550521], [1, 0.4877539730169314], [0, 0.49716404700146805], [0, 0.4971534954574218], [0, 0.5026538793368202], [0, 0.5140184249213177], [0, 0.5026532330171577], [1, 0.4837108814840936], [0, 0.4633182881494274], [1, 0.4970591593659223], [0, 0.471855685553926], [1, 0.4954245366533115], [0, 0.4956315330754817], [1, 0.501301267040366], [1, 0.5018949343436604], [0, 0.49716407121507594], [0, 0.4946386205471032], [0, 0.4803281099424563], [0, 0.509423429817299], [1, 0.5026005234770551], [0, 0.5020007980362774], [1, 0.514424111640332], [0, 0.5097023898083196], [0, 0.47922797720555654], [0, 0.49420832391332503], [1, 0.49706887458802823], [0, 0.4953826614101989], [1, 0.47901500497398375], [0, 0.49542483278909144], [1, 0.5130216663121564], [0, 0.48395799242361986], [0, 0.5026534826045788], [0, 0.48313357394166173], [0, 0.4980097178250666], [0, 0.4971639035824058], [0, 0.5144356299497397], [0, 0.5020856512814983], [0, 0.49819221969411687], [0, 0.491412719468846], [0, 0.4971049714256893], [1, 0.4852780723387925], [1, 0.49472638730606233], [1, 0.4961835859185], [0, 0.502642258619694], [1, 0.45628616363870456], [0, 0.49800970478675716], [0, 0.5026539240390442], [0, 0.49005510758306714], [0, 0.48563410651526656], [0, 0.49528566376409816], [1, 0.5016853335748509], [0, 0.4956704640701368], [1, 0.5135533796334287], [0, 0.5026433314733263], [0, 0.5243175853099633], [0, 0.49714413596989965], [0, 0.4707233891199068], [1, 0.4970290935987303], [1, 0.456324106159998], [0, 0.4821799645747056], [0, 0.48453111881992544], [0, 0.5026532628186409], [0, 0.4508409072639619], [0, 0.49700710585481134], [1, 0.5137926668714319], [0, 0.5026530057808478], [0, 0.5144462400318145], [0, 0.4954245464313796], [1, 0.496477051265025], [0, 0.49716356459189687], [1, 0.4824751947430348], [0, 0.4971550600286651], [1, 0.5144313750258693], [1, 0.45628332725829385], [0, 0.5024206300207779], [0, 0.5024916211648037], [0, 0.49395750079598066], [0, 0.4713726310270532], [0, 0.4844141612154891], [0, 0.49536100535937266], [1, 0.497744569020371], [1, 0.5144462763230744], [0, 0.5026524358274754], [1, 0.45563571083865184], [0, 0.4818323038194281], [0, 0.49704593690750365], [0, 0.4853640122758653], [0, 0.4971495039384193], [1, 0.49716007410735796], [0, 0.49716408052800204], [0, 0.4612834373566531], [0, 0.502570813218843], [0, 0.4971600852828684], [0, 0.46196459258962635], [0, 0.4971639613225477], [1, 0.4997500323433065], [0, 0.4315636695070319], [0, 0.5012486476570857], [1, 0.4681953520483241], [0, 0.5144404701848143], [0, 0.5173330375575069], [0, 0.5026539016879322], [1, 0.4978992578319897], [0, 0.4968970592812985], [0, 0.5099989599058297], [1, 0.46347958525038196], [0, 0.4877542810997906], [0, 0.5003733578375447], [0, 0.5024207902045061], [0, 0.49238498535256525], [0, 0.4985337504306731], [0, 0.49542453711893364], [0, 0.49496188163043525], [0, 0.49800960839639813], [0, 0.476069021931736], [1, 0.4971292483354659], [0, 0.49716396877288865], [0, 0.4974739505690944], [0, 0.49889639757976156], [1, 0.5026539184512663], [0, 0.5026162624002205], [0, 0.4971639743606442], [1, 0.5043189871624743], [0, 0.4747411823963618], [1, 0.4831908350952212], [0, 0.5027772982883902], [0, 0.4954246400214607], [1, 0.5026539035505249], [1, 0.4988833283944991], [0, 0.5013578901211283], [1, 0.47855730258428514], [0, 0.5025592911991945], [0, 0.4758691646260525], [1, 0.47748403865522215], [1, 0.4909945714941979], [1, 0.4950817491224468], [1, 0.5021383445725434], [0, 0.4933901192760148], [1, 0.49712593293652174], [0, 0.4819182635500201], [0, 0.45628145759625], [0, 0.5025834527930274], [0, 0.4971628363210872], [0, 0.498009665206175], [0, 0.49716399671166694], [0, 0.4947463526491909], [1, 0.5023398507941512], [1, 0.4971636707592537], [1, 0.4553596010324063], [0, 0.5144436614908763], [0, 0.47985430461487705], [0, 0.49706090087892424], [0, 0.5026539240390442], [0, 0.5027524942014406], [0, 0.4364492935569561], [1, 0.5024205648297255], [0, 0.45628133652573993], [0, 0.5026538905123762], [1, 0.4971630691442347], [1, 0.5011262483473576], [0, 0.5026539128634882], [1, 0.5025925627463793], [0, 0.4562813642518105], [0, 0.5026479656047084], [0, 0.49219895132673397], [0, 0.4966201719601728], [0, 0.4969339429081329], [0, 0.4712659705614474], [1, 0.5024147889021661], [0, 0.4606998468402347], [0, 0.49524962806849726], [0, 0.45556841926923924], [0, 0.5017224146838462], [1, 0.5144462544552639], [0, 0.50265351799384], [1, 0.4954243774104877], [1, 0.484149122670167], [1, 0.49716409356609875], [0, 0.49026244894430715], [1, 0.48590734125413276], [0, 0.4671828371111211], [0, 0.5023988841437829], [1, 0.4971628009319688], [1, 0.4589812545718148], [1, 0.47126983392638905], [1, 0.4752264519705247], [1, 0.49574740660194466], [1, 0.49716389240689457], [0, 0.41623894735996114], [1, 0.4971604540747117], [0, 0.4563066912061921], [1, 0.5025285397238444], [0, 0.47817863473826805], [1, 0.4969168565789623], [0, 0.45628138828107184], [0, 0.47598764325450216], [0, 0.47668290520495704], [0, 0.4992602677825023], [1, 0.5026538327720032], [0, 0.5025995083628985], [0, 0.48595541994065516], [0, 0.47682877571596527], [0, 0.4401609572166152], [1, 0.49716408984092825], [1, 0.49716022125157794], [0, 0.5026538327720033], [1, 0.4846381042241146], [0, 0.47496576420374864], [1, 0.4555203936616278], [0, 0.4968971477535357], [0, 0.4968844980881606], [0, 0.5232663433991763], [1, 0.5021182712094843], [0, 0.45628140306830967], [1, 0.49716407494024645], [0, 0.46128533419533435], [0, 0.49802926970442923], [0, 0.48561403484294563], [1, 0.49857739370490967], [0, 0.46128760781116074], [0, 0.45630878361976923], [0, 0.4930715637331907], [0, 0.4899848480891757], [1, 0.4877555450772979], [1, 0.5026268605597644], [1, 0.4846623674341861], [1, 0.4927990802181915], [1, 0.4612667315237487], [1, 0.49642131814522117], [0, 0.4777285195527722], [0, 0.5096488535768969], [0, 0.4755045114640758], [1, 0.4457075018946686], [1, 0.4969677151339378], [1, 0.4562835361281785], [0, 0.49693393638912015], [0, 0.5353624071166647], [1, 0.4978690239173582], [0, 0.5026227367770515], [0, 0.45646786146865764], [0, 0.49761418201280305], [1, 0.4494633287695737], [0, 0.4569342668806768], [0, 0.49765735529938476], [0, 0.4949671407412181], [0, 0.5144415905618251], [0, 0.4971595879726603], [0, 0.49234848042979984], [0, 0.48185411081416746], [0, 0.46640653338562227], [1, 0.4971641066041953], [1, 0.5026538905123762], [1, 0.5264690619857387], [0, 0.4971636707592537], [0, 0.4919937987129373], [0, 0.44785475441278244], [0, 0.49716408052800215], [0, 0.4889580988853183], [0, 0.497156926338721], [0, 0.4987933416993533], [0, 0.4593392746004652], [1, 0.4949622932332221], [0, 0.45628243447834066], [0, 0.524717250440282], [1, 0.49716027712913], [0, 0.4769588722048648], [0, 0.48353386979194973], [1, 0.456281355009787], [0, 0.4562940184586852], [0, 0.4842524344039095], [0, 0.4971582133849235], [0, 0.48269100823972594], [0, 0.4987937291272885], [1, 0.4655569183639936], [1, 0.4949257318508334], [0, 0.49716166102985687], [1, 0.48286310918094516], [1, 0.49716199443259573], [0, 0.49716411591712156], [0, 0.4811035928027576], [0, 0.49716234646118856], [0, 0.4922816700963666], [0, 0.5026529703915863], [0, 0.4980130062730577], [1, 0.5026539016879322], [1, 0.49818684629524834], [0, 0.4969667754640322], [0, 0.4606411820540806], [0, 0.5025892734033717], [0, 0.4971612568488864], [0, 0.4369307800349958], [0, 0.4984012822155013], [0, 0.5229592430672351], [0, 0.5009605621277666], [0, 0.49716401906268964], [0, 0.4948931808446584], [0, 0.4954121441187944], [1, 0.5025765593268784], [0, 0.49716405631439414], [0, 0.5026538700238568], [1, 0.5026390270204983], [0, 0.5016893121395802], [1, 0.5026535552456937], [0, 0.4970580082910576], [1, 0.5018726369350898], [0, 0.4609213496923138], [0, 0.4971437597278559], [0, 0.49021310114739314], [0, 0.4562813300563236], [0, 0.43177213834679756], [0, 0.42198658954533347], [0, 0.461286121999333], [0, 0.4524133811271657], [0, 0.5140864070889453], [1, 0.5022397040531013], [0, 0.5026538681612641], [1, 0.48191372092067786], [1, 0.47490203279134696], [1, 0.5064144843340215], [0, 0.4857948782560338], [1, 0.4820738513343853], [0, 0.49716290709932387], [0, 0.45631657473158754], [0, 0.502328740358002], [0, 0.4956307526867496], [1, 0.501896497080476], [1, 0.5026522924078349], [0, 0.4971589193046367], [0, 0.45631767362203285], [0, 0.49621253440685475], [1, 0.4971633708830358], [1, 0.4816691758227296], [0, 0.49716409542868395], [0, 0.4672330517740155], [0, 0.48311858835310356], [0, 0.5144380730986293], [0, 0.46128539529411006], [1, 0.45628211470422286], [0, 0.49716376575109966], [1, 0.4971640451388828], [0, 0.4967930188601518], [1, 0.4939132713442739], [0, 0.4749655138415194], [0, 0.5026529964678842], [0, 0.45628140953772633], [0, 0.49716408984092825], [0, 0.48592861719239994], [0, 0.5026539463901564], [0, 0.4999921694397933], [1, 0.4682902855124414], [1, 0.4969064857664447], [0, 0.5026274547271629], [0, 0.49716410101643954], [1, 0.4971632274639758], [0, 0.4980096433204413], [1, 0.5011661404088618], [0, 0.5026525531708174], [0, 0.4956454562197885], [0, 0.5145440174376734], [1, 0.47514759192692363], [0, 0.49692631752635247], [0, 0.49234207629447885], [0, 0.47126989240599054], [0, 0.4827044869441128], [0, 0.49820523548576673], [0, 0.4971640898409283], [0, 0.49716408797834305], [1, 0.48402610419610675], [1, 0.5144462879548884], [0, 0.45628132543531175], [1, 0.45628132728371645], [1, 0.49716384956743437], [1, 0.4773000212290583], [0, 0.5022755145386346], [1, 0.5017832572398226], [0, 0.5026538923749688], [1, 0.4562815148967986], [0, 0.49419423210441743], [0, 0.49771395801003987], [0, 0.49708705338379783], [0, 0.4971641066041953], [1, 0.49716401161234874], [0, 0.49932222016692535], [1, 0.5026407294307074], [1, 0.4971640488640533], [0, 0.5026503981509833], [0, 0.4562988964246642], [1, 0.5009636867034348], [1, 0.5144460357771562], [0, 0.5026538942375616], [1, 0.5144455165329461], [0, 0.502653942664971], [1, 0.49542805070498325], [0, 0.5992135440818425], [0, 0.4971185533809035], [0, 0.47541587719277106], [0, 0.49542324687959005], [1, 0.497132727642045], [0, 0.5012245898795029], [0, 0.4626100468257947], [0, 0.4618248639238652], [1, 0.49800966520617485], [0, 0.49716365585857214], [0, 0.4934312787960366], [0, 0.49542456459064904], [0, 0.45628243078152986], [1, 0.5011104522641964], [0, 0.4955326757807451], [1, 0.47302890198821806], [0, 0.4562814502026309], [0, 0.49606638787534446], [1, 0.45628141600714295], [1, 0.5007036081527442], [0, 0.5967615639766801], [0, 0.4984268281367002], [1, 0.48706775500169697], [0, 0.49470871696708035], [1, 0.5026538048331131], [1, 0.4712610090850902], [1, 0.5140647807701967], [0, 0.4973152864992985], [1, 0.48332539847107475], [0, 0.4729876341621538], [0, 0.47022408813241595], [0, 0.49716409170351356], [1, 0.4949092882560521], [0, 0.49715610121360665], [0, 0.5026539277642296], [0, 0.49715945200395273], [0, 0.5026539165886735], [1, 0.5026514393403537]]\n",
      "294 1122\n",
      "0.7923728813559322\n"
     ]
    }
   ],
   "source": [
    "# threshold for lfcm\n",
    "evaluate(lfcm_results, 'lfcm')\n",
    "print(lfcm_results)\n",
    "\n",
    "_r = 0\n",
    "_nr = 0\n",
    "for r in lfcm_results:\n",
    "    if r[1] >= 0.47700000000000004:\n",
    "        _r += 1\n",
    "    else:\n",
    "        _nr += 1\n",
    "\n",
    "print(_nr, _r)\n",
    "print((_r) / (_r + _nr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 357 tn: 266 fp: 682 fn: 111\n",
      "precision: 0.343599615014437\n",
      "recall: 0.7628205128205128\n",
      "f1: 0.4737889847378899\n",
      "accuracy: 0.4399717514124294\n",
      "\n",
      "tp: 357 tn: 266 fp: 682 fn: 111\n",
      "precision: 0.343599615014437\n",
      "recall: 0.7628205128205128\n",
      "f1: 0.4737889847378899\n",
      "accuracy: 0.4399717514124294\n"
     ]
    }
   ],
   "source": [
    "def re_evaluate(results, model):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    threshold = 0\n",
    "    for _r in results:\n",
    "        label = _r[0]\n",
    "        softmax_score = _r[1]\n",
    "\n",
    "        if (model) == 'fcm':\n",
    "            threshold = 0.5\n",
    "        elif (model) == 'lfcm':\n",
    "            threshold = 0.5\n",
    "        \n",
    "        if label == 1 and softmax_score >= threshold:\n",
    "                tp += 1\n",
    "        elif label == 1 and softmax_score < threshold:\n",
    "                fn += 1\n",
    "        elif label == 0 and softmax_score < threshold:\n",
    "                tn += 1\n",
    "        elif label == 0 and softmax_score >= threshold:\n",
    "                fp += 1\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + fn + tn + fp) \n",
    "\n",
    "    print('tp:',tp, 'tn:',tn, 'fp:',fp, 'fn:',fn)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "    print('f1:', f1)\n",
    "    print('accuracy:', accuracy)\n",
    "\n",
    "re_evaluate(fcm_results, 'lfcm')\n",
    "print()\n",
    "re_evaluate(fcm_results, 'fcm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_evaluate(fcm_results, 'fcm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
