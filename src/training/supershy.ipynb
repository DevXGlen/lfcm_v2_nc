{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lfcm\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import customTransform\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "checkpoint_file = \"checkpoints/fcm_e4b16.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(filepath):\n",
    "    image = np.zeros((3, 299, 299), dtype=np.float32)\n",
    "    try:\n",
    "        image = customTransform.filepath_to_image(filepath)\n",
    "        image = customTransform.rescale(image, 299)\n",
    "        image = customTransform.preprocess_image_to_np_arr(image)\n",
    "        image = torch.from_numpy(image.copy())\n",
    "    except:\n",
    "        image = np.zeros((3, 299, 299), dtype=np.float32)\n",
    "        image = torch.from_numpy(image.copy())\n",
    "\n",
    "    return image\n",
    "\n",
    "def text_to_tensor(id):\n",
    "    text = np.zeros(150, dtype=np.float32)\n",
    "    try:\n",
    "        filepath = os.getenv('EMBED_TT_PATH')\n",
    "        for i,line in enumerate(open(filepath)):\n",
    "            data = line.strip().split(',')\n",
    "            tweet_id = data[0]\n",
    "\n",
    "            if id == tweet_id:\n",
    "                arr = np.array(list(map(float, data[1:])))\n",
    "                text = arr\n",
    "    except Exception as e:\n",
    "        text = np.zeros(150, dtype=np.float32)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def image_text_to_tensor(id):\n",
    "    image_text = np.zeros(150, dtype=np.float32)\n",
    "    try:\n",
    "        filepath = os.getenv('EMBED_IT_PATH')\n",
    "        for i,line in enumerate(open(filepath)):\n",
    "            data = line.strip().split(',')\n",
    "            tweet_id = data[0]\n",
    "\n",
    "            if id == tweet_id:\n",
    "                arr = np.array(list(map(float, data[1:])))\n",
    "                image_text = arr\n",
    "    except Exception as e:\n",
    "        print('error:',e)\n",
    "        image_text = np.zeros(150, dtype=np.float32)\n",
    "\n",
    "    return image_text.copy()\n",
    "\n",
    "\n",
    "def get_input_tensors(input_data):\n",
    "    image = np.zeros((3, 299, 299), dtype=np.float32)\n",
    "    text = np.zeros(150, dtype=np.float32)  # hidden state dimension of lstm\n",
    "    image_text = np.zeros(150, dtype=np.float32)\n",
    "    comments = np.zeros(150, dtype=np.float32)\n",
    "\n",
    "    if \"image_url\" in input_data:\n",
    "        image = image_to_tensor(input_data[\"image_url\"])\n",
    "    else:\n",
    "        image = torch.from_numpy(image.copy())\n",
    "    \n",
    "    if 'tweet_id' in input_data:\n",
    "        text = text_to_tensor(input_data['tweet_id'])\n",
    "    else:\n",
    "        text = torch.from_numpy(text.copy())\n",
    "    \n",
    "    # text = text.astype(np.float32)\n",
    "\n",
    "    if 'tweet_id' in input_data:\n",
    "        image_text = image_text_to_tensor(input_data['tweet_id'])\n",
    "    else:\n",
    "        image_text = image_text.copy()\n",
    "\n",
    "    # image_text = image_text.astype(np.float32)\n",
    "\n",
    "    comments = torch.from_numpy(comments.copy())\n",
    "    text = torch.from_numpy(text.copy())\n",
    "    image_text = torch.from_numpy(image_text.copy())\n",
    "\n",
    "    return {\n",
    "        \"image\": image,\n",
    "        \"image_text\": image_text,\n",
    "        \"text\": text,\n",
    "        \"comments\": comments,\n",
    "    }\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    model = lfcm.OldModel(gpu=0)\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model = lfcm.OldModel()\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0]).cuda(0)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, input_tensors):\n",
    "    in_ten = input_tensors\n",
    "    image = in_ten[\"image\"]\n",
    "    image_text = in_ten[\"image_text\"]\n",
    "    text = in_ten[\"text\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(image.unsqueeze(0), image_text.unsqueeze(0), text.unsqueeze(0))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensors = get_input_tensors(dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception v3 pretraining: Hardcoded strict=False, Might be omiting layers\n",
      "Inception v3 pretraining: Hardcoded strict=False, Might be omiting layers\n",
      "tensor([[-0.0173, -0.1286]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"tweet_text\": \"Is she daft BC has had a carbon tax in place since July 2008 The PM wasnt even in politics when it was initiated THERE IS NO TRUDEAU CARBON TAX in BC YOU MORON Citizens of Kelowna WERE ALL thinking of you with a crisis in your city amp a village idiot as MP Stay safe \",\n",
    "    \"image_url\": \"\",\n",
    "    \"comments\": [\n",
    "        \"Yes she is shamelessly daft\",\n",
    "        \"Seems you need to be really stunned to qualify for that conservative ideology treatment\",\n",
    "        \"Facts dont matter to these\",\n",
    "        \"Shes a feckless kunt along with her cult climate deniers\",\n",
    "        \"And it has worked marvelously\",\n",
    "        \"CPC MPs do not care if they make sense  it is all about pushing misinformation to discredit the PM\",\n",
    "        \"two thumbs up when they are all gone please post sid by shots to let us know please\",\n",
    "        \"YAAAAWWWWNNN Youre as phoney as Trudeaus carbon taxDildo\",\n",
    "        \"I thought journalists always fact checked their stories Ooops\",\n",
    "        \"Daft is kind for this type of dangerous misinformation\",\n",
    "    ],\n",
    "    \"tweet_id\": \"1693318988380442696\",\n",
    "}\n",
    "model = load_model()\n",
    "input_tensors = get_input_tensors(input_data)\n",
    "prediction = predict(model, input_tensors)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"tweet_text\": \"Is she daft BC has had a carbon tax in place since July 2008 The PM wasnt even in politics when it was initiated THERE IS NO TRUDEAU CARBON TAX in BC YOU MORON Citizens of Kelowna WERE ALL thinking of you with a crisis in your city amp a village idiot as MP Stay safe \",\n",
    "    \"image_url\": \"\",\n",
    "    \"comments\": [\n",
    "        \"Yes she is shamelessly daft\",\n",
    "        \"Seems you need to be really stunned to qualify for that conservative ideology treatment\",\n",
    "        \"Facts dont matter to these\",\n",
    "        \"Shes a feckless kunt along with her cult climate deniers\",\n",
    "        \"And it has worked marvelously\",\n",
    "        \"CPC MPs do not care if they make sense  it is all about pushing misinformation to discredit the PM\",\n",
    "        \"two thumbs up when they are all gone please post sid by shots to let us know please\",\n",
    "        \"YAAAAWWWWNNN Youre as phoney as Trudeaus carbon taxDildo\",\n",
    "        \"I thought journalists always fact checked their stories Ooops\",\n",
    "        \"Daft is kind for this type of dangerous misinformation\",\n",
    "    ],\n",
    "    \"tweet_id\": \"1693318988380442696\",\n",
    "}\n",
    "input_tensors = get_input_tensors(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 150.9930,  150.9930,  150.9930,  ...,  147.9930,  144.9930,\n",
       "           144.9930],\n",
       "         [ 150.9930,  150.9930,  150.9930,  ...,  147.9930,  145.9930,\n",
       "           145.9930],\n",
       "         [ 150.9930,  150.9930,  150.9930,  ...,  150.9930,  147.9930,\n",
       "           147.9930],\n",
       "         ...,\n",
       "         [ 150.9930,  150.9930,  150.9930,  ...,  -93.0070,  -63.0070,\n",
       "             5.9930],\n",
       "         [ 150.9930,  150.9930,  150.9930,  ...,   15.9930,  101.9930,\n",
       "           146.9930],\n",
       "         [ 150.9930,  150.9930,  150.9930,  ...,  131.9930,  135.9930,\n",
       "           128.9930]],\n",
       "\n",
       "        [[ 138.3312,  138.3312,  138.3312,  ...,  138.3312,  138.3312,\n",
       "           138.3312],\n",
       "         [ 138.3312,  138.3312,  138.3312,  ...,  138.3312,  138.3312,\n",
       "           138.3312],\n",
       "         [ 138.3312,  138.3312,  138.3312,  ...,  137.3312,  135.3312,\n",
       "           135.3312],\n",
       "         ...,\n",
       "         [ 138.3312,  138.3312,  138.3312,  ...,  -96.6688,  -70.6688,\n",
       "            -1.6688],\n",
       "         [ 138.3312,  138.3312,  138.3312,  ...,    8.3312,   92.3312,\n",
       "           137.3312],\n",
       "         [ 138.3312,  138.3312,  138.3312,  ...,  124.3312,  124.3312,\n",
       "           118.3312]],\n",
       "\n",
       "        [[ 132.3211,  132.3211,  132.3211,  ...,  131.3211,  129.3211,\n",
       "           129.3211],\n",
       "         [ 132.3211,  132.3211,  132.3211,  ...,  132.3211,  131.3211,\n",
       "           131.3211],\n",
       "         [ 132.3211,  132.3211,  132.3211,  ...,  132.3211,  132.3211,\n",
       "           132.3211],\n",
       "         ...,\n",
       "         [ 132.3211,  132.3211,  132.3211,  ..., -101.6789,  -76.6789,\n",
       "            -7.6789],\n",
       "         [ 132.3211,  132.3211,  132.3211,  ...,    0.3211,   85.3211,\n",
       "           130.3211],\n",
       "         [ 132.3211,  132.3211,  132.3211,  ...,  116.3211,  119.3211,\n",
       "           112.3211]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.3665e-03,  9.8336e-03,  6.2512e-02,  4.0015e-02, -2.1601e-03,\n",
       "         2.4825e-02, -3.9657e-02,  2.7556e-02,  1.0487e-01, -3.4718e-03,\n",
       "        -7.9896e-02, -1.0934e-02,  1.0123e-01,  2.9717e-01,  2.2180e-01,\n",
       "         1.2709e-01, -8.4463e-03,  5.1178e-01, -4.6893e-01, -2.8085e-01,\n",
       "         4.0842e-03,  4.9391e-02,  3.0191e-02, -1.6089e-01, -7.4724e-03,\n",
       "         3.3243e-02, -2.8608e-02, -3.9465e-03, -8.9247e-03, -7.2318e-02,\n",
       "         2.5304e-02, -4.1184e-04, -8.8525e-03, -4.2712e-02,  2.9370e-02,\n",
       "         3.2649e-01,  2.2707e-02, -1.0853e-02,  8.5953e-03,  1.5991e-01,\n",
       "         4.9769e-02,  7.9289e-03, -4.2235e-02, -1.3066e-02, -9.6779e-03,\n",
       "        -1.6154e-02,  2.2624e-02,  2.8407e-01, -1.4514e-01,  4.2968e-02,\n",
       "        -7.2501e-02,  3.7755e-02,  3.6654e-01, -3.0091e-02, -7.2391e-03,\n",
       "         1.6353e-01,  2.7134e-02, -5.0871e-02,  6.5337e-02,  4.8362e-03,\n",
       "         1.2670e-01, -4.1465e-03, -5.4035e-02, -3.9766e-03, -4.5078e-02,\n",
       "         3.5893e-01, -1.3961e-01, -6.8567e-02, -5.3527e-03, -8.0526e-02,\n",
       "         1.4366e-02, -6.7186e-02,  1.2968e-01, -3.0031e-01, -4.9966e-02,\n",
       "         9.3933e-02, -9.4119e-03, -2.3576e-02, -2.1468e-02, -3.4951e-01,\n",
       "        -2.4642e-02,  4.9423e-01,  7.5343e-02,  5.1805e-03,  6.6406e-02,\n",
       "         3.3775e-02,  5.9106e-02,  3.2976e-02,  1.2295e-02,  2.6505e-03,\n",
       "        -5.9722e-01, -2.1590e-02, -5.6144e-03, -3.8972e-01, -1.3587e-04,\n",
       "         7.0817e-02, -9.1744e-02,  3.8925e-02,  4.0217e-01, -5.9249e-03,\n",
       "         2.0126e-01, -1.5194e-02,  4.9296e-02, -1.1507e-01, -2.3356e-03,\n",
       "         6.8152e-02, -3.6692e-03,  7.2134e-03, -1.9732e-02, -3.7032e-03,\n",
       "         3.5494e-02, -7.8495e-03, -2.9649e-01,  7.6666e-03, -3.6554e-02,\n",
       "        -2.8495e-02,  5.5649e-03, -1.6841e-01, -1.4960e-03, -5.4494e-01,\n",
       "        -2.3088e-02,  1.7235e-02,  4.1375e-02, -5.6028e-03, -1.6539e-01,\n",
       "        -6.0787e-02, -5.8742e-03, -4.6985e-02,  1.7697e-02,  5.1222e-03,\n",
       "         3.1263e-02,  1.5637e-02,  1.9590e-02, -7.8323e-02, -8.5308e-03,\n",
       "        -1.5478e-01, -2.2863e-01,  2.8688e-03, -1.4356e-02,  1.3570e-01,\n",
       "         5.8916e-03, -4.7328e-02, -1.6436e-02, -2.7366e-01,  1.2635e-02,\n",
       "         5.6973e-02,  3.2415e-02,  1.0968e-02, -3.5240e-03,  1.5834e-02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0349, -0.3688, -0.2289, -0.2531, -0.3144, -0.1638,  0.0070, -0.3749,\n",
       "        -0.1362, -0.0282, -0.2794,  0.1125,  0.3155, -0.0216,  0.3642,  0.0322,\n",
       "        -0.0636, -0.1054, -0.4663, -0.2764,  0.3828,  0.2129,  0.4273, -0.4804,\n",
       "         0.0863, -0.0198,  0.1996,  0.0611,  0.1697,  0.3256, -0.0072,  0.1485,\n",
       "         0.1177,  0.0783,  0.2742,  0.1788, -0.4421, -0.1873,  0.0389, -0.4962,\n",
       "        -0.1433, -0.0109, -0.3560, -0.3070,  0.0098, -0.2011, -0.3037,  0.3213,\n",
       "        -0.3695,  0.0084, -0.3305,  0.0211,  0.0382, -0.3180,  0.3647,  0.4145,\n",
       "         0.2649,  0.2046, -0.2747, -0.2274,  0.0073,  0.0336, -0.1146,  0.1170,\n",
       "         0.1001,  0.3465,  0.2782, -0.0322,  0.0253,  0.0297,  0.4198, -0.5326,\n",
       "         0.3701, -0.4183, -0.4745,  0.1805,  0.0984, -0.2897, -0.3507,  0.4974,\n",
       "         0.3743,  0.1803,  0.1201, -0.2476,  0.0435, -0.4809,  0.4869, -0.2047,\n",
       "        -0.0063,  0.2796,  0.1696, -0.0494, -0.1329, -0.3734, -0.3793, -0.0420,\n",
       "         0.1840, -0.0030, -0.0413, -0.1257,  0.0173, -0.3446, -0.3977,  0.0887,\n",
       "        -0.3491, -0.0576, -0.1828,  0.0311,  0.2881, -0.1984,  0.4725, -0.0031,\n",
       "         0.1734, -0.3983, -0.0139,  0.0607, -0.2269,  0.2562,  0.3545, -0.2175,\n",
       "        -0.2126,  0.1313,  0.3635, -0.2108,  0.0311,  0.4475,  0.4618,  0.3084,\n",
       "        -0.5784,  0.0792, -0.0295,  0.4138, -0.2584,  0.3617, -0.3016,  0.0250,\n",
       "        -0.5106, -0.2895, -0.0709,  0.4680, -0.0025,  0.3589,  0.0431,  0.3236,\n",
       "         0.0692,  0.1090, -0.3971, -0.4021, -0.4273,  0.0628])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors['image_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 568\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0, 1, 0.001)\n",
    "# thresholds = np.arange(0.4, 0.44, 0.0000001)\n",
    "\n",
    "example_weight = [-0.0505,  0.2211]\n",
    "racist_score = example_weight[1]\n",
    "not_racist_score = example_weight[0]\n",
    "\n",
    "softmax_hate_score = np.exp(racist_score) / (np.exp(racist_score) + np.exp(not_racist_score))\n",
    "r = 0\n",
    "nr = 0\n",
    "for th in thresholds:\n",
    "    if softmax_hate_score >= th:\n",
    "        r += 1\n",
    "    elif softmax_hate_score < th:\n",
    "        nr = 0\n",
    "\n",
    "# print(thresholds)\n",
    "print(nr, r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
