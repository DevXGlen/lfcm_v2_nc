{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import customDataset\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import lfcm\n",
    "import torch.nn as nn \n",
    "from pylab import zeros\n",
    "import torch.backends.cudnn as cudnn\n",
    "import trainingFunctionsLFCM as t\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getenv('ROOT_PATH')\n",
    "split_train = 'train.csv'\n",
    "split_val = 'valid.csv'\n",
    "batch_size = 24 # 32\n",
    "workers = 4\n",
    "gpu = 0\n",
    "gpus = [0]\n",
    "weights = [0.33209667, 0.66790333] \n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "optimizer_name = 'ADAM'\n",
    "epochs = 32 # 301\n",
    "start_epoch = 0\n",
    "ImgSize = 299\n",
    "print_freq = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception v3 pretraining: Hardcoded strict=False, Might be omiting layers\n"
     ]
    }
   ],
   "source": [
    "model = lfcm.LFCM(gpu=gpu)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights).cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ADAM optimizer\n",
      "Using ADAM optimizer with: CNN lr: 1e-07 , mm_lr: 1e-06\n"
     ]
    }
   ],
   "source": [
    "if optimizer_name == 'ADAM':\n",
    "    print(\"Using ADAM optimizer\")\n",
    "    lr = 1e-6\n",
    "    cnn_lr = 1e-7\n",
    "\n",
    "if optimizer_name == 'ADAM':\n",
    "    print(\"Using ADAM optimizer with: CNN lr: \" + str(cnn_lr) + \" , mm_lr: \" + str(lr) )\n",
    "    optimizer = torch.optim.Adam([\n",
    "                    {'params': model.mm.parameters()},\n",
    "                    {'params': model.cnn.parameters(), 'lr': cnn_lr}],\n",
    "                                lr = lr)\n",
    "\n",
    "# print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model, device_ids=gpus).cuda(gpu)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset.CustomDatasetLFCM(root_dir, split_train, Rescale=0, RandomCrop=299, Mirror=True, embed_dir='train_embeddings')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9434"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     if train_dataset[i][3][0] != 0:\n",
    "#         print(f\"{i}\", train_dataset[i][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = customDataset.CustomDatasetLFCM(\n",
    "    root_dir, split_val, Rescale=ImgSize,RandomCrop=0,Mirror=False, embed_dir='valid_embeddings')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     if val_dataset[i][2][] == 0:\n",
    "#         print(f\"{i}\", val_dataset[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(val_dataset)):\n",
    "#     if val_dataset[i][3][0] == 0:\n",
    "#         print(val_dataset[i][3])\n",
    "#         break\n",
    "\n",
    "# print(val_dataset[45][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "plot_data['train_loss'] = zeros(epochs)\n",
    "plot_data['train_acc'] = zeros(epochs)\n",
    "plot_data['train_acc_racist'] = zeros(epochs)\n",
    "plot_data['train_acc_notRacist'] = zeros(epochs)\n",
    "plot_data['train_acc_avg'] = zeros(epochs)\n",
    "plot_data['val_loss'] = zeros(epochs)\n",
    "plot_data['val_acc'] = zeros(epochs)\n",
    "plot_data['val_acc_racist'] = zeros(epochs)\n",
    "plot_data['val_acc_notRacist'] = zeros(epochs)\n",
    "plot_data['val_acc_avg'] = zeros(epochs)\n",
    "plot_data['epoch'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfcm_v2_b16_toy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbatch_size\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs):\n\u001b[0;32m      9\u001b[0m     plot_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m epoch\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "is_best = True\n",
    "val_acc_avg_best = 0\n",
    "epoch_best = -1\n",
    "epoch_loss_best = 0\n",
    "model_name = 'lfcm_v2_b16_toy'\n",
    "best_loss = 0\n",
    "print(batch_size)\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    plot_data['epoch'] = epoch\n",
    "\n",
    "    print('Epoch:', epoch)\n",
    "    t.train(train_loader, model, criterion, optimizer, epoch, print_freq, plot_data, gpu)\n",
    "\n",
    "    plot_data = t.validate(val_loader, model, criterion, print_freq, plot_data, gpu)\n",
    "\n",
    "    if (plot_data['val_acc_avg'][epoch]) > val_acc_avg_best:\n",
    "        t.save_checkpoint(model, is_best, filename=f'checkpoints/{model_name}')\n",
    "        epoch_best = epoch\n",
    "        val_acc_avg_best = plot_data['val_acc_avg'][epoch]\n",
    "\n",
    "    # if best_loss == 0:\n",
    "    #     print('loss:', plot_data['val_loss'][epoch])\n",
    "    #     t.save_checkpoint(model, is_best, filename=f'checkpoints/val_loss_{model_name}')\n",
    "    #     epoch_loss_best = epoch\n",
    "    #     best_loss = plot_data['val_loss'][epoch]\n",
    "\n",
    "    # if (plot_data['val_loss'][epoch]) < best_loss:\n",
    "    #     print('loss:', plot_data['val_loss'][epoch])\n",
    "    #     t.save_checkpoint(model, is_best, filename=f'checkpoints/val_loss_{model_name}')\n",
    "    #     epoch_loss_best = epoch\n",
    "    #     best_loss = plot_data['val_loss'][epoch]\n",
    "    \n",
    "print(f'best model avg acc epoch: {model_name} epoch: {epoch_best} batch_size: {batch_size}')\n",
    "# print(f'best model loss epoch: {model_name} epoch: {epoch_best} batch_size: {batch_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
